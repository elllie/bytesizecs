---
title: "1. Computers aren't demigods"
parent: "2. You & AI"
has_children: false
has_toc: false
nav_order: 2
---

# 2-1: Computers aren't demigods / On the existence of bias-free systems

Computers just do what flawed humans tell them to do—they’re not capable of original thought, and they’re certainly not capable of thinking about things at a higher level than any human. In this byte, software engineering researcher David Widder explains the pitfalls of placing too much trust in computers.

(iframe)

## This byte's guest: [David Widder](http://davidwidder.me/)

<img src="https://se-phd.isri.cmu.edu/images/people/students/widder-david.jpg" width="250">

David Gray Widder is a researcher at Carnegie Mellon working to understand how software engineers think about the effect Artificial Intelligence is having in their workplace and our political society. He is a painter working on conflicts between appropriation, inspiration, and his own cultural identity in contemporary portraiture.

<a class="twitter-timeline" data-height="350" data-dnt="true" href="https://twitter.com/davidthewid?ref_src=twsrc%5Etfw">Tweets by davidthewid</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## Further reading

* [Algorithmic Impact Assessments](https://ainowinstitute.org/aiareport2018.pdf) from the [AI Now Institute](https://ainowinstitute.org/)
* [Original ProPublica piece about racist risk assessment tools](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), using data from Florida courts
* [A more recent analysis adding nuance to the above ProPublica article](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/)
* [Coded Bias: A documentary on the social implications and harms of AI](https://www.codedbias.com/virtualcinema)
